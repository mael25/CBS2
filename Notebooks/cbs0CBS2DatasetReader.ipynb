{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260f5e7b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Data inspector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e1e9a8",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3947ca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage2/mwildi/CBS2\n"
     ]
    }
   ],
   "source": [
    "#To be at project directory root and not in the Notebooks folder\n",
    "%cd /storage2/mwildi/CBS2\n",
    "\n",
    "#Imports\n",
    "import lmdb\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdce5de",
   "metadata": {},
   "source": [
    "## 1. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30425ea4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 786 repetitions\n",
      "Found 623 train episodes and 161 val episodes\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset/13dec\"\n",
    "repetitions = [x[0] for x in os.walk(dataset_path)][1:]\n",
    "print('Found {} repetitions'.format(len(repetitions)))\n",
    "#print(repetitions)\n",
    "train_paths = [x[0] for x in os.walk(dataset_path + os.path.sep + 'train')][1:]\n",
    "val_paths = [x[0] for x in os.walk(dataset_path + os.path.sep + 'val')][1:]\n",
    "print('Found {} train episodes and {} val episodes'.format(len(train_paths), len(val_paths)))\n",
    "#print(val_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad29c3",
   "metadata": {},
   "source": [
    "### 1.1 Decode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec88939",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decode_dataset(path):\n",
    "    lmdb_env = lmdb.open(path)\n",
    "    lmdb_txn = lmdb_env.begin()\n",
    "    lmdb_cursor = lmdb_txn.cursor()\n",
    "\n",
    "    out = dict()\n",
    "    for key, value in tqdm(lmdb_cursor):\n",
    "        out[key.decode(\"utf-8\")] = value\n",
    "\n",
    "    lmdb_cursor.close()\n",
    "    return out\n",
    "\n",
    "def decode_data(data, kind='rgb'):\n",
    "    if kind == 'loc' or kind == 'rot' or kind == 'spd' or kind == 'cmd' or kind == 'cam_location':\n",
    "        return np.frombuffer(data, dtype=np.float32)\n",
    "\n",
    "    img = np.frombuffer(data, dtype=np.uint8)\n",
    "\n",
    "    if kind == 'trafficlights':\n",
    "        #return np.frombuffer(data, dtype=np.int8)\n",
    "        return int.from_bytes(data, 'little')\n",
    "    elif kind == 'rgb':\n",
    "        img = img.reshape((160, 384, 3))\n",
    "    elif kind == 'segmentation':\n",
    "        img = img.reshape((160, 384))\n",
    "    elif kind == 'birdview':\n",
    "        img = img.reshape((96, 96, -1))\n",
    "    else:\n",
    "        # raise ValueError(f\"Not known type {kind}. Choose from: rgb, birdview, segmentation.\")\n",
    "        raise ValueError(\"Not known type {}. Choose from: rgb, birdview, segmentation.\".format(kind))\n",
    "\n",
    "    return img\n",
    "\n",
    "def decode_frame(step):\n",
    "    data = {'rgb':None, 'segmentation': None, 'birdview': None, 'loc': None, 'rot': None, 'spd': None, 'cmd': None, 'trafficlights': None, 'cam_location': None}\n",
    "\n",
    "    for t in data.keys():\n",
    "        # d = out[f\"{t}_{step:04d}\"]\n",
    "        d = dataset[\"{}_{:04d}\".format(t, step)]\n",
    "        data[t] = decode_data(d, kind=t)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db8280f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_red_tl():\n",
    "    is_red_tl = []\n",
    "    speed = []\n",
    "    for i in range(int(dataset['len'].decode())):\n",
    "        is_red_tl.append(decode_frame(i)['trafficlights'])\n",
    "    c = Counter(is_red_tl)\n",
    "    n_red_frames = c[0]\n",
    "    n_frames = sum(c.values())\n",
    "    \n",
    "    level_changes = 0\n",
    "    for i,tl in enumerate(is_red_tl):\n",
    "        if (i != 0 and tl != old_tl):\n",
    "            level_changes += 1\n",
    "        old_tl = tl\n",
    "    red_lights = math.floor(level_changes/2)\n",
    "    infos = [red_lights, n_red_frames, n_frames]\n",
    "    \n",
    "    return infos\n",
    "\n",
    "def get_red_tl_by_cmd():\n",
    "    is_red_tl = []\n",
    "    speed = []\n",
    "    for i in range(int(dataset['len'].decode())):\n",
    "        if decode_frame(i)['trafficlights']:\n",
    "            cmd = int(decode_frame(i)['cmd'])\n",
    "            is_red_tl.append(cmd)\n",
    "        else:\n",
    "            is_red_tl.append(0)\n",
    "    c = Counter(is_red_tl)\n",
    "    print(c)\n",
    "    no_red = c[0]\n",
    "    red_l = c[1]\n",
    "    red_r = c[2]\n",
    "    red_s = c[3]\n",
    "    red_f = c[4]\n",
    "    n_frames = sum(c.values())\n",
    "    n_red_frames = n_frames - no_red\n",
    "    \n",
    "    level_changes = 0\n",
    "    for i,tl in enumerate(is_red_tl):\n",
    "        if (i != 0 and tl != old_tl):\n",
    "            level_changes += 1\n",
    "        old_tl = tl\n",
    "    red_lights = math.floor(level_changes/2)\n",
    "    infos = [red_lights, n_red_frames, n_frames, red_l, red_r, red_s, red_f]\n",
    "    \n",
    "    return infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07bc182a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_list = val_paths[:3]\n",
    "filename = 'val2.txt'\n",
    "#ox, oy, oz, ori_ox, ori_oy, vx, vy, vz, _, _, _, _, _, _, ax, ay, az, cmd, steer, throttle, brake, manual, gear  = measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a2ed8c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep.0/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2531it [00:00, 91010.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2531\n",
      "Counter({0: 253})\n",
      "[0, 0, 253, 0, 0, 0, 0]\n",
      "ep.1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3551it [00:00, 98509.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3551\n",
      "Counter({0: 355})\n",
      "[0, 0, 355, 0, 0, 0, 0]\n",
      "ep.2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6431it [00:00, 121503.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6431\n",
      "Counter({0: 643})\n",
      "[0, 0, 643, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_episodes = len(path_list)\n",
    "episodes_tl_infos = np.zeros((n_episodes, 3))\n",
    "with open(filename,\"w\") as savefile:     \n",
    "    for i, path in enumerate(path_list):\n",
    "        print('ep.{}/{}'.format(i, n_episodes))\n",
    "        dataset = decode_dataset(path)\n",
    "        print(len(dataset))\n",
    "        if len(dataset) != 0:\n",
    "            #row = get_red_tl()\n",
    "            row = get_red_tl_by_cmd()\n",
    "            print(row)\n",
    "            np.savetxt(savefile, row, fmt='%i', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f796c8a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_tl_infos(filename):\n",
    "    retrieved = np.fromfile(filename, sep='\\n').astype(int).reshape(-1,3)\n",
    "    print('Retrieved {} episodes'.format(retrieved.shape[0]))\n",
    "    red_lights = retrieved[:,0]\n",
    "    n_red_frames = retrieved[:,1]\n",
    "    n_frames = retrieved[:,2]\n",
    "    return red_lights, n_red_frames, n_frames\n",
    "\n",
    "def retrieve_tl_infos_cmd(filename):\n",
    "    retrieved = np.fromfile(filename, sep='\\n').astype(int).reshape(-1,7)\n",
    "    print('Retrieved {} episodes'.format(retrieved.shape[0]))\n",
    "    #print(retrieved)\n",
    "    retrieved = np.sum(retrieved, axis=0) # Sum over all epsisodes\n",
    "    total_infractions = retrieved[0]\n",
    "    total_frames = retrieved[1] # Store total number of frames to compute rates PER FRAME\n",
    "    rates = 100*retrieved[3:]/total_frames # Compute rates\n",
    "    return total_frames, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69ac8b2b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 episodes\n",
      "Retrieved 3 episodes\n",
      "[nan nan nan nan]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mwildi/anaconda3/envs/cbsmerged/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_lights_t, percentages_t = retrieve_tl_infos_cmd('val2.txt')\n",
    "red_lights_v, percentages_v = retrieve_tl_infos_cmd('val2.txt')\n",
    "\n",
    "print(percentages_v)\n",
    "print(sum(percentages_v)) #Should be 100%\n",
    "legends = ['Left', 'Right', 'Straight', 'Follow lane']\n",
    "x_title = 'Dataset'\n",
    "plot_labels = ['Training', 'Validation']\n",
    "\n",
    "metrics = pd.DataFrame(np.array([percentages_t, percentages_v]), columns=legends)\n",
    "ax = metrics.plot(kind='bar', figsize=(12, 7), legend=True, fontsize=16)\n",
    "ax.set_xlabel(x_title)\n",
    "x = np.arange(len(plot_labels))\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(plot_labels, fontsize=16, rotation='horizontal')\n",
    "ax.set_ylabel(\"Ratio $red_{cmd}$ / $red_{total}$ [%]\", fontsize=16)\n",
    "plt.title(\"Frames with red light by directional command\", fontsize=20, weight='bold')\n",
    "plt.savefig('command_rtl_comp.png')\n",
    "\n",
    "#red_lights, n_red_frames, n_frames, red_l, red_r, red_s, red_f = retrieve_tl_infos('test.txt')\n",
    "#red_lights, n_red_frames, n_frames, red_l, red_r, red_s, red_f = retrieve_tl_infos('val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa3160",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(n_red_frames_t)/sum(n_frames_t))\n",
    "print(sum(n_red_frames_v)/sum(n_frames_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a471b1a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_red_frames_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37a99a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg_tl = np.mean(tl)\n",
    "avg_rate = np.mean(tl_frames_percentage)\n",
    "print(avg_tl, avg_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f009d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.boxplot(data=[tl_t.astype('float'), tl_v.astype('float')])\n",
    "ax = sns.boxplot(..., labels=[\"Metric\", \"Length\"])\n",
    "plt.ylabel(\"Red traffic lights per episode\", size=14)\n",
    "plt.xlabel(\"Dataset\", size=14)\n",
    "plt.title(\"Repartition of red traffic lights in train and val dataset\", size=18)\n",
    "plt.savefig(\"comprtl.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aac2f9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = [tl_t, tl_t]\n",
    "fig7, ax7 = plt.subplots()\n",
    "ax7.set_title('Multiple Samples with Different sizes')\n",
    "ax7.boxplot(data)\n",
    "ax7.legend(labels=['dsdssd','dssd'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eca673",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tl_perc_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8caa82",
   "metadata": {},
   "source": [
    "### 1.2 Explore dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e58dc",
   "metadata": {},
   "source": [
    "### 1.2 Inspect traffic lights state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9e4ab",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "is_red_tl = []\n",
    "speed = []\n",
    "for i in range(int(out['len'].decode())):\n",
    "    is_red_tl.append(decode_frame(i)['trafficlights'])\n",
    "    meas = decode_frame(i)['measurements']\n",
    "    # Measurements: [ox, oy, oz, ori_ox, ori_oy, vx, vy, vz, _, _, _, _, _, _, ax, ay, az, cmd, steer, throttle, brake, manual, gear]\n",
    "    vel = meas[5:8]\n",
    "    speed.append(np.linalg.norm(vel))\n",
    "\n",
    "c = Counter(is_red_tl)\n",
    "total = sum(c.values())\n",
    "mapping = {1: 'Red', 0:'Green/Yellow/None'}\n",
    "print([\"{}: {} ({})%\".format(mapping.get(k, k), round(v / total * 100, 1), v) for k, v in c.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11ff08",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(range(len(is_red_tl)),is_red_tl, 'r--')\n",
    "ax.set_xlabel(\"Frame\")\n",
    "ax.set_ylabel(\"Red light\", color='red')\n",
    "\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(range(len(is_red_tl)), speed, 'b')\n",
    "ax2.set_ylabel(\"Speed [m/s]\", color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db78a5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frames_with_red = []\n",
    "for i in range(len(is_red_tl)):\n",
    "    if(is_red_tl[i]==1):\n",
    "        frames_with_red.append(i)\n",
    "frames_with_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94449893",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frame_of_interest = decode_frame(700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04bfc36",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rgb=frame_of_interest['rgb']\n",
    "resized = cv2.resize(rgb, (int(rgb.shape[1]/2), int(rgb.shape[0]/2)), interpolation = cv2.INTER_AREA)\n",
    "cv2.imwrite('a.png', cv2.cvtColor(resized, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354515f6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(frame_of_interest['segmentation'][:,:,0]==12) # Carla TL semantic seg channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa488d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(rgb)\n",
    "plt.axis('off')\n",
    "plt.savefig('rgb.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410f7b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a=frame_of_interest['segmentation'][:, :, 0]\n",
    "plt.imshow(a)\n",
    "plt.axis('off')\n",
    "plt.savefig('seg.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b417686",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bv=frame_of_interest['birdview']\n",
    "print(bv.shape[0:2])\n",
    "b=np.zeros(bv.shape[0:2])\n",
    "for k in range(bv.shape[2]):\n",
    "    b[bv[:,:,k] != 0] = k\n",
    "    #mask[..., i][seg == i] = 1\n",
    "plt.imshow(b)\n",
    "plt.axis('off')\n",
    "plt.savefig('bv.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662600a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Red Traffic light birdview binary mask\n",
    "plt.imshow(frame_of_interest['birdview'][:,:,2])\n",
    "plt.axis('off')\n",
    "plt.savefig('bvtl.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d2ad0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_frame(frame, i):\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (int(0.1*frame.shape[0]), int(0.9*frame.shape[0]))\n",
    "    fontScale              = 1\n",
    "    fontColor              = [0,255,0]\n",
    "    fontColor2              = [255,0,0]\n",
    "    lineType               = 2\n",
    "    printed_frame = cv2.putText(frame.copy(),'Frame: '+str(i), \n",
    "            bottomLeftCornerOfText, font, fontScale, fontColor, lineType);\n",
    "    return printed_frame\n",
    "\n",
    "video = cv2.VideoWriter('videos/dataset_23_09_overview.avi', 0, 10, (384, 160))\n",
    "for i in range(int(out['len'].decode())):\n",
    "    drawn_frame = draw_frame(decode_frame(i)['rgb'], i)\n",
    "    video.write(drawn_frame)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb49370",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#from IPython.core.display import Video\n",
    "#Video(\"videos/dataset_23_09_overview.mp4\", embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e5c59",
   "metadata": {},
   "source": [
    "## 2. Waypoints computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a5d22",
   "metadata": {},
   "source": [
    "### 2.1 Tools for transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df729e8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Location():\n",
    "    def __init__(self, x, y, z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "    def __repr__(self,):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self,):\n",
    "        return \"Location(x={}, y={}, z={})\".format(self.x, self.y, self.z)\n",
    "\n",
    "class Rotation():\n",
    "    def __init__(self, p, y, r):\n",
    "        self.pitch = p\n",
    "        self.yaw = y\n",
    "        self.roll = r\n",
    "\n",
    "    def __repr__(self,):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Rotation(pitch={}, yaw={}, roll={})\".format(self.pitch, self.yaw, self.roll)\n",
    "\n",
    "class Transform():\n",
    "    def __init__(self, loc, rot):\n",
    "        self.location = loc\n",
    "        self.rotation = rot\n",
    "\n",
    "    def __repr__(self,):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self,):\n",
    "        return \"Transform({}, {})\".format(self.location, self.rotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7da42f",
   "metadata": {},
   "source": [
    "### 2.2 Compute waypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcdc16",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def project_vehicle(x, y, z, ori_x, ori_y, ori_z):\n",
    "    pos = np.array([x,y,z])\n",
    "    ori = np.array([ori_x, ori_y, ori_z])\n",
    "    ori /= np.linalg.norm(ori)  # Make unit vector\n",
    "\n",
    "    new_pos = pos + 4 * ori\n",
    "    return converter.convert(np.array([new_pos]))\n",
    "\n",
    "def interpolate_waypoints(points):\n",
    "    points = points[:, :2]\n",
    "\n",
    "    # Fit cubic function through points\n",
    "    z = np.polyfit(points[:, 0], points[:, 1], 2)\n",
    "    p = np.poly1d(z)\n",
    "\n",
    "    # Keep interpolating until we have 5 points\n",
    "    while points.shape[0] < 5:\n",
    "        points_2 = np.vstack([points[0], points[:-1]])\n",
    "        max_id = np.argmax(np.linalg.norm(points-points_2, axis=1))\n",
    "        _x = np.mean([points[max_id], points_2[max_id]], axis=0)[0]\n",
    "        points = np.insert(points, max_id, np.array([_x, p(_x)]), 0)\n",
    "\n",
    "    return points\n",
    "\n",
    "def get_waypoints(REF_FRAME, world_x, world_y, world_z, ori_x, ori_y, ori_z, GAP=5):\n",
    "    if decode_frame(REF_FRAME)['trafficlights']:\n",
    "        vehicle_proj = project_vehicle(world_x, world_y, world_z, ori_x, ori_y, ori_z)\n",
    "        output = np.array([vehicle_proj[0] for _ in range(5)])\n",
    "        return output\n",
    "\n",
    "    output = []\n",
    "    for i in range(REF_FRAME, (REF_FRAME + (N_STEP+1+BUFFER*GAP)), GAP):\n",
    "        if len(output) == N_STEP:\n",
    "            break\n",
    "\n",
    "        x, y, z = decode_frame(i)['measurements'][:3]\n",
    "        image_coords = converter.convert(np.array([[x, y, z]]))\n",
    "        if len(image_coords) > 0:\n",
    "            output.append(image_coords[0])\n",
    "\n",
    "    if len(output) < 2:\n",
    "        # First try with smaller GAP\n",
    "        if GAP == 5:\n",
    "            return get_waypoints(REF_FRAME, world_x, world_y, world_z, ori_x, ori_y, ori_z, GAP=1)\n",
    "\n",
    "        vehicle_proj = project_vehicle(world_x, world_y, world_z, ori_x, ori_y, ori_z)\n",
    "        output = np.array([vehicle_proj[0] for _ in range(5)])\n",
    "        return output\n",
    "\n",
    "    if len(output) >= 2 and len(output) < 5:\n",
    "        return interpolate_waypoints(np.array(output))\n",
    "\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a4dfd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# REF_FRAME = 800\n",
    "N_STEP = 5\n",
    "BUFFER = 40\n",
    "N_DATASET_CATEGORIES = 9 #(used to be 7)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "all_wp = []\n",
    "#N = int((len(out)-1)/7)\n",
    "N = int((len(out)-1)/N_DATASET_CATEGORIES) - 1\n",
    "for frame in tqdm(range(N - (N_STEP * BUFFER) - 1)):\n",
    "        # Extract world coordinates from dataset\n",
    "        world_coords = decode_frame(frame)['measurements']\n",
    "        world_x, world_y, world_z, ori_x, ori_y, ori_z, _, _, _, cam_x, cam_y, cam_z, cam_yaw, cam_roll, cam_pitch = world_coords[:15]\n",
    "\n",
    "        sensor_transform = Transform(Location(cam_x, cam_y, cam_z), Rotation(cam_yaw, cam_roll, cam_pitch))\n",
    "        converter = CoordinateConverter(sensor_transform, fov=120)\n",
    "\n",
    "        image_coord_wp = get_waypoints(frame, world_x, world_y, world_z, ori_x, ori_y, ori_z)\n",
    "\n",
    "        all_wp.append(image_coord_wp[:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9bfa35",
   "metadata": {},
   "source": [
    "## 3. Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d406cae",
   "metadata": {},
   "source": [
    "### 3.1 Segmentation from 2D to ND "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ece8d8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 13\n",
    "N_CLASSES_COMBINED = 6\n",
    "KEEP_CLASSES = {4,6,7,10,12}\n",
    "N_TRAFFIC_LIGHT_STATES = 1\n",
    "\n",
    "def seg2D_to_ND_combined(seg, tl_info):\n",
    "    seg = seg[:, :, 0]  # CARLA stores segmentation values in R channel\n",
    "    mask = np.zeros((*seg.shape, N_CLASSES_COMBINED + N_TRAFFIC_LIGHT_STATES))\n",
    "\n",
    "    for i, seg_class in enumerate(KEEP_CLASSES):\n",
    "        mask[..., i][seg == seg_class] = 1\n",
    "\n",
    "    TO_COMBINE = set(range(N_CLASSES))-KEEP_CLASSES\n",
    "    for i in TO_COMBINE:\n",
    "        mask[..., len(KEEP_CLASSES)] += seg==i\n",
    "\n",
    "    if tl_info == 0:\n",
    "        return mask\n",
    "\n",
    "    # Select channel and set binary mask, 12 is traffic sign class\n",
    "    mask[..., N_CLASSES_COMBINED][seg == 12] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "def seg2D_to_ND(seg, tl_info, combine=False):\n",
    "    \"\"\"Converts 2D segmentation image to ND array with N boolean masks.\n",
    "    Where N corresponds to number of segmentation classes.\"\"\"\n",
    "    if combine:\n",
    "        return seg2D_to_ND_combined(seg, tl_info)\n",
    "\n",
    "    seg = seg[:, :, 0]  # CARLA stores segmentation values in R channel\n",
    "    mask = np.zeros((*seg.shape, N_CLASSES + N_TRAFFIC_LIGHT_STATES))\n",
    "\n",
    "    for i in range(N_CLASSES):\n",
    "        mask[..., i][seg == i] = 1\n",
    "\n",
    "    if tl_info == 0:\n",
    "        return mask\n",
    "\n",
    "    # Select channel and set binary mask, 12 is traffic sign class\n",
    "    mask[..., N_CLASSES][seg == 12] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "#UNUSED\n",
    "def seg2D_to_ND_new(seg, tl_info, combine=False):\n",
    "    \"\"\"Converts 2D segmentation image to ND array with N boolean masks.\n",
    "    Where N corresponds to number of segmentation classes.\"\"\"\n",
    "    if combine:\n",
    "        return seg2D_to_ND_combined(seg, tl_info)\n",
    "\n",
    "    seg = seg[:, :, 0]  # CARLA stores segmentation values in R channel\n",
    "    mask = np.zeros((*seg.shape, N_CLASSES))\n",
    "\n",
    "    # Do not add traffic light state yet\n",
    "    for i in range(N_CLASSES-1):\n",
    "        mask[..., i][seg == i] = 1\n",
    "\n",
    "    # Add traffic light state, 12 is traffic sign class\n",
    "    mask[..., 12][seg == 12] = tl_info\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec70aa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_CLASSES=5\n",
    "a= np.random.randint(N_CLASSES, size=(10,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02095ff",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask = np.zeros((*a.shape, N_CLASSES))\n",
    "mask.shape\n",
    "\n",
    "# Do not add traffic light state yet\n",
    "for i in range(N_CLASSES):\n",
    "    mask[..., i][a == i] = 5\n",
    "    print(mask[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82767ca3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask[:,:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad62de",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tc = seg2D_to_ND_combined(decode_frame(N)['segmentation'], decode_frame(N)['trafficlights'])\n",
    "plt.imshow(tc[..., -2])\n",
    "plt.show()\n",
    "tc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52100ff1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = seg2D_to_ND(decode_frame(N)['segmentation'], decode_frame(N)['trafficlights'], combine=False)\n",
    "plt.imshow(t[..., -2])\n",
    "plt.show()\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb35427a",
   "metadata": {},
   "source": [
    "### 3.2 Down-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f056822",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def down_scale(img):\n",
    "    new_shape = (img.shape[0]//2, img.shape[1]//2)\n",
    "    img = np.moveaxis(img, 1, 0)\n",
    "    img = cv2.resize(img.astype(np.float32), new_shape)\n",
    "    img = np.moveaxis(img, 1, 0)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab0bb2",
   "metadata": {},
   "source": [
    "### 3.3 Augmentation sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274fd14",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "\n",
    "#def affine(image):\n",
    "#    aug = iaa.Affine(translate_px={\"x\": (-30, 30), \"y\": (0, -5)}, scale={\"x\": (1, 1.15), \"y\": (1, 1.15)}, mode='reflect')\n",
    "#    return aug(images=image)\n",
    "\n",
    "# def dropout(image):\n",
    "#     aug = iaa.Dropout(p=(0, 0.1), per_channel=0.5)\n",
    "#     return aug(images=image)\n",
    "\n",
    "# def blur(image):\n",
    "#     aug = iaa.MotionBlur(k=5, angle=[-90, 0, 90])\n",
    "#     return aug(images=image)\n",
    "\n",
    "sometimes = lambda aug: iaa.Sometimes(0.33, aug)\n",
    "# seq = iaa.Affine(translate_px={\"x\": (-15, 15), \"y\": (0, -5)}, scale={\"x\": (1, 1.15), \"y\": (1, 1.15)}, mode='reflect')\n",
    "seq = iaa.Sequential(\n",
    "        [\n",
    "            sometimes(\n",
    "                iaa.Affine(\n",
    "                    translate_px={\"x\": (-15, 15), \"y\": (0, -5)},\n",
    "                    scale={\"x\": (1, 1.15), \"y\": (1, 1.15)},\n",
    "                    mode='reflect')\n",
    "            ),\n",
    "            sometimes(\n",
    "                iaa.Dropout(\n",
    "                    p=(0, 0.1),\n",
    "                    per_channel=0.5)\n",
    "            ),\n",
    "            sometimes(\n",
    "                iaa.MotionBlur(\n",
    "                    k=(3,5),\n",
    "                    angle=[-90, 0, 90])\n",
    "            )\n",
    "        ],\n",
    "    random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3afe782",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Keypoint objects from waypoints so that we can apply to them the same augmentation sequence as the image\n",
    "def points_to_keypoints(points, shape):\n",
    "    kps = KeypointsOnImage([\n",
    "        Keypoint(x=points[0][0], y=points[0][1]),\n",
    "        Keypoint(x=points[1][0], y=points[1][1]),\n",
    "        Keypoint(x=points[2][0], y=points[2][1]),\n",
    "        Keypoint(x=points[3][0], y=points[3][1]),\n",
    "        Keypoint(x=points[4][0], y=points[4][1])\n",
    "        ], shape=shape)\n",
    "\n",
    "    return kps\n",
    "\n",
    "# Apply augmentation sequence to both image and waypoints\n",
    "def augment_image(image, points, redo=0):\n",
    "    if redo >= 5:\n",
    "        print(\"J\")\n",
    "        return image, points\n",
    "\n",
    "    image_aug, p_aug = seq(image=down_scale(image), keypoints=points_to_keypoints(points/2, (80, 192)))\n",
    "    temp = p_aug.to_xy_array()\n",
    "    if not np.all((temp[:, 0] <= 192) & (temp[:, 1] <= 80)):\n",
    "        return augment_image(image, points, redo=redo+1)\n",
    "\n",
    "    return image_aug, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445dfa3b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# view image (before/after) augmentation\n",
    "\n",
    "# def plot_augmentation(original, augmented):\n",
    "#     plt.figure(figsize=(12,6))\n",
    "#     plt.title(\"Original\")\n",
    "#     plt.imshow(original)\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure(figsize=(12,6))\n",
    "#     plt.title(\"Augmented\")\n",
    "#     plt.imshow(augmented)\n",
    "#     plt.show()\n",
    "    \n",
    "# # Intermediate overview\n",
    "# b = decode_frame(1)['segmentation']\n",
    "# b = seg2D_to_ND(b, 0)\n",
    "# b = down_scale(b)\n",
    "\n",
    "# plot_augmentation(b[:, :, 6:9], seq(image=b)[:, : ,6:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2878e300",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# view waypoints after augmentation\n",
    "\n",
    "# for i in range(0, 500, 100):\n",
    "#     temp_img = decode_frame(i)['segmentation']\n",
    "#     temp_img = seg2D_to_ND(temp_img, 0)\n",
    "#     img_aug, points_aug = augment_image(temp_img, all_wp[i])\n",
    "#     plt.scatter(points_aug[:, 0], points_aug[:, 1])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371211",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imgs, new_kps = seq(images=[down_scale(decode_frame(i)['segmentation'][:, :, 0]) for i in range(245, 255, 10)], keypoints=[points_to_keypoints(all_wp[i]/2, (80, 192)) for i in range(0, 100, 10)])\n",
    "for img, new_kp in zip(imgs, new_kps):\n",
    "    plt.imshow(img)\n",
    "    points_temp = new_kp.to_xy_array()\n",
    "    plt.scatter(points_temp[:, 0], points_temp[:, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee03e5",
   "metadata": {},
   "source": [
    "## 4. Final results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c1749",
   "metadata": {},
   "source": [
    "### 4.1 View final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190f9f1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_results(ref_frame_id, next_frame_id, locations):\n",
    "    plt.title(\"NEXT FRAME ({})\".format(next_frame_id))\n",
    "    plt.imshow(decode_frame(next_frame_id)['segmentation'][:, :, 0])\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.title(\"REF FRAME ({}) WITH PROJECTIONS\".format(ref_frame_id))\n",
    "    plt.imshow(decode_frame(ref_frame_id)['segmentation'][:, :, 0])\n",
    "    for i, location in enumerate(locations):\n",
    "        plt.scatter(location[:, 0], location[:, 1], label=\"projection {}\".format(i))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdac1b0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#plot_results(N, i, [all_wp[N]])\n",
    "plot_results(155, 160, [all_wp[155]])\n",
    "# plt.imshow(down_scale(decode_frame(N)['segmentation'][:, :, 0]))\n",
    "# temp_wp = all_wp[N].copy()\n",
    "\n",
    "# temp_wp /= 2\n",
    "# # temp_wp[:, 0] /= 2\n",
    "# # temp_wp[:, 1] /= 2\n",
    "\n",
    "# plt.scatter(temp_wp[:, 0], temp_wp[:, 1], s=1)\n",
    "# plt.scatter(temp_wp[:, 0], temp_wp[:, 1]-2, s=1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5fa8dd",
   "metadata": {},
   "source": [
    "### 4.2 Save final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489254fb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "R = 1\n",
    "\n",
    "#video = cv2.VideoWriter('imgs_noise_test/test_video_noise_2.avi', 0, 10, (192, 80))\n",
    "video = cv2.VideoWriter('noise/test_video_noise_2.avi', 0, 10, (192, 80))\n",
    "\n",
    "for i, wp in tqdm(enumerate(all_wp)):\n",
    "    # Down-scaling image (x0.5)\n",
    "    img = down_scale(decode_frame(i)['segmentation'][:, :, 0])\n",
    "    # Accordingly down-scaling waypoints (x0.5)\n",
    "    for x, y in wp:\n",
    "        x = int(x/2)\n",
    "        y = int(y/2)\n",
    "        img[y - R: y + R + 1, x - R: x + R + 1] = 12\n",
    "    \n",
    "    norm_image = cv2.normalize(img, None, alpha=0, beta=250, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "    imgC = cv2.applyColorMap(norm_image, cv2.COLORMAP_JET)\n",
    "    #plt.imshow(imgC)\n",
    "    #plt.show()\n",
    "    video.write(imgC)\n",
    "    #cv2.imwrite('imgs_noise_test/frame_{}.png'.format(i),  imgC)\n",
    "    cv2.imwrite('noise/frame_{}.png'.format(i),  imgC)\n",
    "    \n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a825e7",
   "metadata": {},
   "source": [
    "## 5. Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81319f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PIXEL_OFFSET = 10\n",
    "\n",
    "def draw_msra_gaussian(heatmap, center, sigma):\n",
    "    tmp_size = sigma * 3\n",
    "    mu_x = int(center[0] + 0.5)\n",
    "    mu_y = int(center[1] + 0.5)\n",
    "    w, h = heatmap.shape[0], heatmap.shape[1]\n",
    "    ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]\n",
    "    br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]\n",
    "    if ul[0] >= h or ul[1] >= w or br[0] < 0 or br[1] < 0:\n",
    "        return heatmap\n",
    "    size = 2 * tmp_size + 1\n",
    "    x = np.arange(0, size, 1, np.float32)\n",
    "    y = x[:, np.newaxis]\n",
    "    x0 = y0 = size // 2\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "    g_x = max(0, -ul[0]), min(br[0], h) - ul[0]\n",
    "    g_y = max(0, -ul[1]), min(br[1], w) - ul[1]\n",
    "    img_x = max(0, ul[0]), min(br[0], h)\n",
    "    img_y = max(0, ul[1]), min(br[1], w)\n",
    "    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(\n",
    "      heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]],\n",
    "      g[g_y[0]:g_y[1], g_x[0]:g_x[1]])\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def world_to_pixel(\n",
    "        x,y,ox,oy,ori_ox, ori_oy,\n",
    "        pixels_per_meter=5, offset=(-80,160), size=320, angle_jitter=15):\n",
    "    pixel_dx, pixel_dy = (x-ox)*pixels_per_meter, (y-oy)*pixels_per_meter\n",
    "\n",
    "    pixel_x = pixel_dx*ori_ox+pixel_dy*ori_oy\n",
    "    pixel_y = -pixel_dx*ori_oy+pixel_dy*ori_ox\n",
    "\n",
    "    pixel_x = size-pixel_x\n",
    "\n",
    "    return np.array([pixel_x, pixel_y]) + offset\n",
    "\n",
    "def test_get_item(bird_view, segmentation, tl_info, measurement, segs=False):\n",
    "    crop_x_jitter = 5\n",
    "    crop_y_jitter = 0\n",
    "    angle_jitter =  5\n",
    "    img_size = 320\n",
    "    crop_size = 192\n",
    "    crop_size_y = 80\n",
    "    down_ratio = 4\n",
    "    gap = 5\n",
    "    gaussian_radius = 1.0\n",
    "    n_step = 5\n",
    "    segmentation = seg2D_to_ND(segmentation, tl_info, combine=False)\n",
    "    rgb_image = None\n",
    "\n",
    "    ox, oy, oz, ori_ox, ori_oy, vx, vy, vz, _, _, _, _, _, _, ax, ay, az, cmd, steer, throttle, brake, manual, gear  = measurement\n",
    "    speed = np.linalg.norm([vx,vy,vz])\n",
    "\n",
    "    oangle = np.arctan2(ori_oy, ori_ox)\n",
    "    delta_angle = np.random.randint(-angle_jitter,angle_jitter+1)\n",
    "    dx = np.random.randint(-crop_x_jitter,crop_x_jitter+1)\n",
    "    dy = np.random.randint(0,crop_y_jitter+1) - PIXEL_OFFSET\n",
    "\n",
    "    o_camx = ox + ori_ox*2\n",
    "    o_camy = oy + ori_oy*2\n",
    "\n",
    "#     if segs:\n",
    "    pixel_ox = 192\n",
    "    pixel_oy = 130\n",
    "\n",
    "    # RANDOM WARPING\n",
    "    segmentation = cv2.warpAffine(\n",
    "            segmentation,\n",
    "            cv2.getRotationMatrix2D((pixel_ox,pixel_oy), delta_angle, 1.0),\n",
    "            segmentation.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    center_x, center_y = pixel_ox, pixel_oy-crop_size_y//2\n",
    "    segmentation = segmentation[\n",
    "            dy+center_y-crop_size_y//2:dy+center_y+crop_size_y//2,\n",
    "            dx+center_x-crop_size//2:dx+center_x+crop_size//2]\n",
    "\n",
    "    angle = np.arctan2(ori_oy, ori_ox) + np.deg2rad(delta_angle)\n",
    "    ori_ox, ori_oy = np.cos(angle), np.sin(angle)\n",
    "\n",
    "    locations = []\n",
    "    orientations = []\n",
    "\n",
    "    # LOCATION MODIFICATION\n",
    "    for dt in range(gap, gap*(n_step+1), gap):\n",
    "        f_measurement = decode_frame(N+dt)['measurements']\n",
    "        x, y, z, ori_x, ori_y = f_measurement[:5]\n",
    "#         x, y, z, ori_x, ori_y, ori_z = f_measurement[:6]\n",
    "#         rot, loc = rotation(ori_x, ori_y, ori_z), np.array([x, y, z])\n",
    "#         inv_m = get_inv_matrix(rot, loc)\n",
    "\n",
    "        pixel_y, pixel_x = world_to_pixel(x,y,ox,oy,ori_ox,ori_oy,size=160, offset=(-80,192))\n",
    "        pixel_x = pixel_x - (384-crop_size)//2\n",
    "        pixel_y = crop_size_y - (160-pixel_y)+70\n",
    "\n",
    "        pixel_x -= dx\n",
    "        pixel_y -= dy\n",
    "\n",
    "        angle = np.arctan2(ori_y, ori_x) - np.arctan2(ori_oy, ori_ox)\n",
    "        ori_dx, ori_dy = np.cos(angle), np.sin(angle)\n",
    "\n",
    "        locations.append([x, y, z])\n",
    "        orientations.append([ori_dx, ori_dy])\n",
    "\n",
    "\n",
    "    # Create mask\n",
    "    output_size = crop_size // down_ratio\n",
    "    heatmap_mask = np.zeros((n_step, output_size, output_size), dtype=np.float32)\n",
    "    regression_offset = np.zeros((n_step,2), np.float32)\n",
    "    indices = np.zeros((n_step), dtype=np.int64)\n",
    "\n",
    "    for i, (pixel_x, pixel_y, _) in enumerate(locations):\n",
    "        center = np.array(\n",
    "                [pixel_x / down_ratio, pixel_y / down_ratio],\n",
    "                dtype=np.float32)\n",
    "        center = np.clip(center, 0, output_size-1)\n",
    "        center_int = np.rint(center)\n",
    "\n",
    "        draw_msra_gaussian(heatmap_mask[i], center_int, gaussian_radius)\n",
    "        regression_offset[i] = center - center_int\n",
    "        indices[i] = center_int[1] * output_size + center_int[0]\n",
    "    out = []\n",
    "    out.append([segmentation, bird_view, np.array(locations), cmd, speed])\n",
    "#     else:\n",
    "    pixel_ox = 160\n",
    "    pixel_oy = 260\n",
    "\n",
    "\n",
    "    # RANDOM WARPING\n",
    "    bird_view = cv2.warpAffine(\n",
    "            bird_view,\n",
    "            cv2.getRotationMatrix2D((pixel_ox,pixel_oy), delta_angle, 1.0),\n",
    "            bird_view.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "    # RANDOM CROPPING\n",
    "    center_x, center_y = 160, 260-crop_size//2\n",
    "    bird_view = bird_view[\n",
    "            dy+center_y-crop_size//2:dy+center_y+crop_size//2,\n",
    "            dx+center_x-crop_size//2:dx+center_x+crop_size//2]\n",
    "\n",
    "    angle = np.arctan2(ori_oy, ori_ox) + np.deg2rad(delta_angle)\n",
    "    ori_ox, ori_oy = np.cos(angle), np.sin(angle)\n",
    "\n",
    "    locations = []\n",
    "    orientations = []\n",
    "\n",
    "    # LOCATION MODIFICATION\n",
    "    for dt in range(gap, gap*(n_step+1), gap):\n",
    "        f_measurement = decode_frame(N+dt)['measurements']\n",
    "        x, y, z, ori_x, ori_y = f_measurement[:5]\n",
    "\n",
    "#         x, y, z, ori_x, ori_y, ori_z = f_measurement[:6]\n",
    "#         rot, loc = rotation(ori_x, ori_y, ori_z), np.array([x, y, z])\n",
    "#         inv_m = get_inv_matrix(rot, loc)\n",
    "\n",
    "        pixel_y, pixel_x = world_to_pixel(x,y,ox,oy,ori_ox,ori_oy,size=img_size)\n",
    "        pixel_x = pixel_x - (img_size-crop_size)//2\n",
    "        pixel_y = crop_size - (img_size-pixel_y)+70\n",
    "\n",
    "        pixel_x -= dx\n",
    "        pixel_y -= dy\n",
    "\n",
    "        angle = np.arctan2(ori_y, ori_x) - np.arctan2(ori_oy, ori_ox)\n",
    "        ori_dx, ori_dy = np.cos(angle), np.sin(angle)\n",
    "\n",
    "        locations.append([x, y, z])\n",
    "        orientations.append([ori_dx, ori_dy])\n",
    "\n",
    "\n",
    "    # Create mask\n",
    "    output_size = crop_size // down_ratio\n",
    "    heatmap_mask = np.zeros((n_step, output_size, output_size), dtype=np.float32)\n",
    "    regression_offset = np.zeros((n_step,2), np.float32)\n",
    "    indices = np.zeros((n_step), dtype=np.int64)\n",
    "\n",
    "    for i, (pixel_x, pixel_y, _) in enumerate(locations):\n",
    "        center = np.array(\n",
    "                [pixel_x / down_ratio, pixel_y / down_ratio],\n",
    "                dtype=np.float32)\n",
    "        center = np.clip(center, 0, output_size-1)\n",
    "        center_int = np.rint(center)\n",
    "\n",
    "        draw_msra_gaussian(heatmap_mask[i], center_int, gaussian_radius)\n",
    "        regression_offset[i] = center - center_int\n",
    "        indices[i] = center_int[1] * output_size + center_int[0]\n",
    "\n",
    "    out.append([segmentation, bird_view, np.array(locations), cmd, speed])\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c23cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_FIG = 6\n",
    "out_temp = []\n",
    "for i in range(N_FIG):\n",
    "    N = i + 10\n",
    "    temp = test_get_item(decode_frame(N)['birdview'], decode_frame(N)['segmentation'], decode_frame(N)['trafficlights'], decode_frame(N)['measurements'])\n",
    "    out_temp.append(temp)\n",
    "\n",
    "out_temp = np.array(out_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bf0be",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "REF_FRAME = 0\n",
    "NEXT_FRAME = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579d89a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extract world coordinates from dataset\n",
    "world_coords = decode_frame(REF_FRAME)['measurements']\n",
    "world_x, world_y, world_z, _, _, _, _, _, cam_x, cam_y, cam_z, cam_yaw, cam_roll, cam_pitch = world_coords[:14]\n",
    "\n",
    "print(\"CURRENT LOCATION:\", world_x, world_y, world_z)\n",
    "# Get sensor transform\n",
    "sensor_transform = Transform(Location(cam_x, cam_y, cam_z), Rotation(cam_yaw, cam_roll, cam_pitch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2c7c1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,60))\n",
    "\n",
    "for i in range(N_FIG):\n",
    "    # NEW SEG\n",
    "    plt.subplot(N_FIG, 2, (i*2)+1)\n",
    "    plt.imshow(out_temp[i][0][0][..., 6:9])\n",
    "    plt.scatter(out_temp[i][0][2][:,0], out_temp[i][0][2][:,1])\n",
    "\n",
    "    # OLD BIRDVIEW\n",
    "    plt.subplot(N_FIG, 2, (i*2)+2)\n",
    "    plt.imshow(out_temp[i][1][1][:, :, :3])\n",
    "    plt.scatter(out_temp[i][1][2][:,0], out_temp[i][1][2][:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef408e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,20))\n",
    "\n",
    "for i in range(N_FIG):\n",
    "    # NEW SEG\n",
    "    plt.subplot(N_FIG, 2, (i*2)+1)\n",
    "    plt.imshow(out_temp[i][0][0][..., 6:9])\n",
    "    plt.scatter(out_temp[i][0][2][:,0], out_temp[i][0][2][:,1])\n",
    "\n",
    "    # OLD BIRDVIEW\n",
    "    plt.subplot(N_FIG, 2, (i*2)+2)\n",
    "    plt.imshow(out_temp[i][1][1][:, :, :3])\n",
    "    plt.scatter(out_temp[i][1][2][:,0], out_temp[i][1][2][:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86a0868",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Segemetnation tests\n",
    "\n",
    "for i in range(1000):\n",
    "    temp_img = decode_frame(i)['segmentation']\n",
    "    temp_tl = decode_frame(i)['trafficlights']\n",
    "    \n",
    "    if temp_tl:\n",
    "        print(i)\n",
    "        break\n",
    "    \n",
    "\n",
    "temp_img = decode_frame(759)['segmentation']\n",
    "temp_tl = decode_frame(759)['trafficlights']\n",
    "\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(temp_img[:, :, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"OLD TL state channel\")\n",
    "plt.imshow(seg2D_to_ND(temp_img, 1)[:, :, 13:14])\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"OLD TL channel\")\n",
    "plt.imshow(seg2D_to_ND(temp_img, 1)[:, :, 12:13])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"NEW TL (state) channel\")\n",
    "plt.imshow(seg2D_to_ND_new(temp_img, 0)[:, :, 12:13])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(seg2D_to_ND_new(temp_img, 0)[:, :, 10:13])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
