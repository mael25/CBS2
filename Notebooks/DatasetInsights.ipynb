{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260f5e7b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Data inspector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e1e9a8",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3947ca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage2/mwildi/myLBS\n"
     ]
    }
   ],
   "source": [
    "#To be at project directory root and not in the Notebooks folder\n",
    "%cd /storage2/mwildi/myLBS\n",
    "\n",
    "#Imports\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import Counter\n",
    "import cv2\n",
    "from bird_view.utils.image_utils import CoordinateConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdce5de",
   "metadata": {},
   "source": [
    "## 1. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30425ea4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 142 train episodes and 33 val episodes\n",
      "['datasets/dataset_thomas_7juni/val/016', 'datasets/dataset_thomas_7juni/val/021', 'datasets/dataset_thomas_7juni/val/023', 'datasets/dataset_thomas_7juni/val/003', 'datasets/dataset_thomas_7juni/val/024', 'datasets/dataset_thomas_7juni/val/011', 'datasets/dataset_thomas_7juni/val/025', 'datasets/dataset_thomas_7juni/val/005', 'datasets/dataset_thomas_7juni/val/012', 'datasets/dataset_thomas_7juni/val/013', 'datasets/dataset_thomas_7juni/val/010', 'datasets/dataset_thomas_7juni/val/019', 'datasets/dataset_thomas_7juni/val/022', 'datasets/dataset_thomas_7juni/val/000', 'datasets/dataset_thomas_7juni/val/006', 'datasets/dataset_thomas_7juni/val/027', 'datasets/dataset_thomas_7juni/val/032', 'datasets/dataset_thomas_7juni/val/009', 'datasets/dataset_thomas_7juni/val/007', 'datasets/dataset_thomas_7juni/val/028', 'datasets/dataset_thomas_7juni/val/020', 'datasets/dataset_thomas_7juni/val/018', 'datasets/dataset_thomas_7juni/val/008', 'datasets/dataset_thomas_7juni/val/015', 'datasets/dataset_thomas_7juni/val/017', 'datasets/dataset_thomas_7juni/val/014', 'datasets/dataset_thomas_7juni/val/004', 'datasets/dataset_thomas_7juni/val/001', 'datasets/dataset_thomas_7juni/val/029', 'datasets/dataset_thomas_7juni/val/030', 'datasets/dataset_thomas_7juni/val/002', 'datasets/dataset_thomas_7juni/val/031', 'datasets/dataset_thomas_7juni/val/026']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"datasets/dataset_thomas_7juni\"\n",
    "train_paths = [x[0] for x in os.walk(dataset_path + os.path.sep + 'train')][1:]\n",
    "val_paths = [x[0] for x in os.walk(dataset_path + os.path.sep + 'val')][1:]\n",
    "print('Found {} train episodes and {} val episodes'.format(len(train_paths), len(val_paths)))\n",
    "print(val_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad29c3",
   "metadata": {},
   "source": [
    "### 1.1 Decode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec88939",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decode_dataset(path):\n",
    "    lmdb_env = lmdb.open(path)\n",
    "    lmdb_txn = lmdb_env.begin()\n",
    "    lmdb_cursor = lmdb_txn.cursor()\n",
    "\n",
    "    out = dict()\n",
    "    for key, value in tqdm(lmdb_cursor):\n",
    "        out[key.decode(\"utf-8\")] = value\n",
    "\n",
    "    lmdb_cursor.close()\n",
    "    return out\n",
    "\n",
    "'''def decode_dataset(paths):\n",
    "    outout = dict()\n",
    "    n_episodes = len(paths)\n",
    "    for i, path in enumerate(paths):\n",
    "        print('ep.{}/{}'.format(i+1, n_episodes))\n",
    "        lmdb_env = lmdb.open(path)\n",
    "        lmdb_txn = lmdb_env.begin()\n",
    "        lmdb_cursor = lmdb_txn.cursor()\n",
    "        \n",
    "        for key, value in tqdm(lmdb_cursor):\n",
    "            out[key.decode(\"utf-8\")] = value\n",
    "            \n",
    "        lmdb_cursor.close()\n",
    "    return out'''\n",
    "\n",
    "def decode_data(data, kind='rgb'):\n",
    "    if kind == 'control' or kind == 'measurements':\n",
    "        return np.frombuffer(data, dtype=np.float32)\n",
    "\n",
    "    img = np.frombuffer(data, dtype=np.uint8)\n",
    "\n",
    "    if kind == 'trafficlights':\n",
    "        return int.from_bytes(data, 'little')\n",
    "\n",
    "    if kind == 'rgb' or kind == 'segmentation':\n",
    "        img = img.reshape((160, 384, 3))\n",
    "    elif kind == 'birdview':\n",
    "        img = img.reshape((320, 320, 7))\n",
    "    else:\n",
    "        # raise ValueError(f\"Not known type {kind}. Choose from: rgb, birdview, segmentation.\")\n",
    "        raise ValueError(\"Not known type {}. Choose from: rgb, birdview, segmentation.\".format(kind))\n",
    "\n",
    "    return img\n",
    "\n",
    "def decode_frame(step):\n",
    "    data = {'rgb':None, 'birdview':None, 'control': None, 'measurements': None, 'segmentation': None, 'trafficlights': None}\n",
    "\n",
    "    for t in data.keys():\n",
    "        d = dataset[\"{}_{:04d}\".format(t, step)]\n",
    "        data[t] = decode_data(d, kind=t)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db8280f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def get_red_tl():\n",
    "    is_red_tl = []\n",
    "    speed = []\n",
    "    for i in range(int(dataset['len'].decode())):\n",
    "        is_red_tl.append(decode_frame(i)['trafficlights'])\n",
    "    c = Counter(is_red_tl)\n",
    "    n_red_frames = c[0]\n",
    "    n_frames = sum(c.values())\n",
    "    \n",
    "    level_changes = 0\n",
    "    for i,tl in enumerate(is_red_tl):\n",
    "        if (i != 0 and tl != old_tl):\n",
    "            level_changes += 1\n",
    "        old_tl = tl\n",
    "    red_lights = math.floor(level_changes/2)\n",
    "    infos = [red_lights, n_red_frames, n_frames]\n",
    "    \n",
    "    return infos\n",
    "\n",
    "def get_red_tl_by_cmd():\n",
    "    is_red_tl = []\n",
    "    speed = []\n",
    "    for i in range(int(dataset['len'].decode())):\n",
    "        if decode_frame(i)['trafficlights']:\n",
    "            cmd = int(decode_frame(i)['measurements'][18])\n",
    "            is_red_tl.append(cmd)\n",
    "        else:\n",
    "            is_red_tl.append(0)\n",
    "    c = Counter(is_red_tl)\n",
    "    print(c)\n",
    "    no_red = c[0]\n",
    "    red_l = c[1]\n",
    "    red_r = c[2]\n",
    "    red_s = c[3]\n",
    "    red_f = c[4]\n",
    "    n_frames = sum(c.values())\n",
    "    n_red_frames = n_frames - no_red\n",
    "    \n",
    "    level_changes = 0\n",
    "    for i,tl in enumerate(is_red_tl):\n",
    "        if (i != 0 and tl != old_tl):\n",
    "            level_changes += 1\n",
    "        old_tl = tl\n",
    "    red_lights = math.floor(level_changes/2)\n",
    "    infos = [red_lights, n_red_frames, n_frames, red_l, red_r, red_s, red_f]\n",
    "    \n",
    "    return infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07bc182a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_list = val_paths\n",
    "filename = 'val2.txt'\n",
    "#ox, oy, oz, ori_ox, ori_oy, vx, vy, vz, _, _, _, _, _, _, ax, ay, az, cmd, steer, throttle, brake, manual, gear  = measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2ed8c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep.0/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8464it [00:20, 408.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8464\n",
      "Counter({0: 587, 3: 320, 4: 302})\n",
      "[3, 622, 1209, 0, 0, 320, 302]\n",
      "ep.1/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1406it [00:00, 4485.05it/s]"
     ]
    }
   ],
   "source": [
    "n_episodes = len(path_list)\n",
    "episodes_tl_infos = np.zeros((n_episodes, 3))\n",
    "with open(filename,\"w\") as savefile:     \n",
    "    for i, path in enumerate(path_list):\n",
    "        print('ep.{}/{}'.format(i, n_episodes))\n",
    "        dataset = decode_dataset(path)\n",
    "        print(len(dataset))\n",
    "        if len(dataset) != 0:\n",
    "            \n",
    "            #row = get_red_tl()\n",
    "            row = get_red_tl_by_cmd()\n",
    "            print(row)\n",
    "            np.savetxt(savefile, row, fmt='%i', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a78b140",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#save_tl_data(train_paths,'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a86a61",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#save_tl_data(train_paths, 'val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2f796c8a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_tl_infos(filename):\n",
    "    retrieved = np.fromfile(filename, sep='\\n').astype(int).reshape(-1,3)\n",
    "    print('Retrieved {} episodes'.format(retrieved.shape[0]))\n",
    "    red_lights = retrieved[:,0]\n",
    "    n_red_frames = retrieved[:,1]\n",
    "    n_frames = retrieved[:,2]\n",
    "    return red_lights, n_red_frames, n_frames\n",
    "\n",
    "def retrieve_tl_infos_cmd(filename):\n",
    "    retrieved = np.fromfile(filename, sep='\\n').astype(int).reshape(-1,7)\n",
    "    print('Retrieved {} episodes'.format(retrieved.shape[0]))\n",
    "    #print(retrieved)\n",
    "    retrieved = np.sum(retrieved, axis=0) # Sum over all epsisodes\n",
    "    total_infractions = retrieved[0]\n",
    "    total_frames = retrieved[1] # Store total number of frames to compute rates PER FRAME\n",
    "    rates = 100*retrieved[3:]/total_frames # Compute rates\n",
    "    return total_frames, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "69ac8b2b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 142 episodes\n",
      "Retrieved 33 episodes\n",
      "[ 8.5656737   2.29778437  8.05152126 81.08502067]\n",
      "100.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_lights_t, percentages_t = retrieve_tl_infos_cmd('test_s.txt')\n",
    "red_lights_v, percentages_v = retrieve_tl_infos_cmd('val_s.txt')\n",
    "\n",
    "print(percentages)\n",
    "print(sum(percentages)) #Should be 100%\n",
    "legends = ['Left', 'Right', 'Straight', 'Follow lane']\n",
    "x_title = 'Dataset'\n",
    "plot_labels = ['Training', 'Validation']\n",
    "\n",
    "metrics = pd.DataFrame(np.array([percentages_t, percentages_v]), columns=legends)\n",
    "ax = metrics.plot(kind='bar', figsize=(12, 7), legend=True, fontsize=16)\n",
    "ax.set_xlabel(x_title)\n",
    "x = np.arange(len(plot_labels))\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(plot_labels, fontsize=16, rotation='horizontal')\n",
    "ax.set_ylabel(\"Ratio $red_{cmd}$ / $red_{total}$ [%]\", fontsize=16)\n",
    "plt.title(\"Frames with red light by directional command\", fontsize=20, weight='bold')\n",
    "plt.savefig('command_rtl_comp.png')\n",
    "\n",
    "#red_lights, n_red_frames, n_frames, red_l, red_r, red_s, red_f = retrieve_tl_infos('test.txt')\n",
    "#red_lights, n_red_frames, n_frames, red_l, red_r, red_s, red_f = retrieve_tl_infos('val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44aa3160",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_red_frames_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-7b847cb5134b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_red_frames_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_frames_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_red_frames_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_frames_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_red_frames_t' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(n_red_frames_t)/sum(n_frames_t))\n",
    "print(sum(n_red_frames_v)/sum(n_frames_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a471b1a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_red_frames_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37a99a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg_tl = np.mean(tl)\n",
    "avg_rate = np.mean(tl_frames_percentage)\n",
    "print(avg_tl, avg_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f009d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.boxplot(data=[tl_t.astype('float'), tl_v.astype('float')])\n",
    "ax = sns.boxplot(..., labels=[\"Metric\", \"Length\"])\n",
    "plt.ylabel(\"Red traffic lights per episode\", size=14)\n",
    "plt.xlabel(\"Dataset\", size=14)\n",
    "plt.title(\"Repartition of red traffic lights in train and val dataset\", size=18)\n",
    "plt.savefig(\"comprtl.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aac2f9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = [tl_t, tl_t]\n",
    "fig7, ax7 = plt.subplots()\n",
    "ax7.set_title('Multiple Samples with Different sizes')\n",
    "ax7.boxplot(data)\n",
    "ax7.legend(labels=['dsdssd','dssd'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eca673",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tl_perc_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8caa82",
   "metadata": {},
   "source": [
    "### 1.2 Explore dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e58dc",
   "metadata": {},
   "source": [
    "### 1.2 Inspect traffic lights state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9e4ab",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "is_red_tl = []\n",
    "speed = []\n",
    "for i in range(int(out['len'].decode())):\n",
    "    is_red_tl.append(decode_frame(i)['trafficlights'])\n",
    "    meas = decode_frame(i)['measurements']\n",
    "    # Measurements: [ox, oy, oz, ori_ox, ori_oy, vx, vy, vz, _, _, _, _, _, _, ax, ay, az, cmd, steer, throttle, brake, manual, gear]\n",
    "    vel = meas[5:8]\n",
    "    speed.append(np.linalg.norm(vel))\n",
    "\n",
    "c = Counter(is_red_tl)\n",
    "total = sum(c.values())\n",
    "mapping = {1: 'Red', 0:'Green/Yellow/None'}\n",
    "print([\"{}: {} ({})%\".format(mapping.get(k, k), round(v / total * 100, 1), v) for k, v in c.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11ff08",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(range(len(is_red_tl)),is_red_tl, 'r--')\n",
    "ax.set_xlabel(\"Frame\")\n",
    "ax.set_ylabel(\"Red light\", color='red')\n",
    "\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(range(len(is_red_tl)), speed, 'b')\n",
    "ax2.set_ylabel(\"Speed [m/s]\", color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db78a5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frames_with_red = []\n",
    "for i in range(len(is_red_tl)):\n",
    "    if(is_red_tl[i]==1):\n",
    "        frames_with_red.append(i)\n",
    "frames_with_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94449893",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frame_of_interest = decode_frame(700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04bfc36",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rgb=frame_of_interest['rgb']\n",
    "resized = cv2.resize(rgb, (int(rgb.shape[1]/2), int(rgb.shape[0]/2)), interpolation = cv2.INTER_AREA)\n",
    "cv2.imwrite('a.png', cv2.cvtColor(resized, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354515f6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(frame_of_interest['segmentation'][:,:,0]==12) # Carla TL semantic seg channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa488d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(rgb)\n",
    "plt.axis('off')\n",
    "plt.savefig('rgb.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410f7b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a=frame_of_interest['segmentation'][:, :, 0]\n",
    "plt.imshow(a)\n",
    "plt.axis('off')\n",
    "plt.savefig('seg.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b417686",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bv=frame_of_interest['birdview']\n",
    "print(bv.shape[0:2])\n",
    "b=np.zeros(bv.shape[0:2])\n",
    "for k in range(bv.shape[2]):\n",
    "    b[bv[:,:,k] != 0] = k\n",
    "    #mask[..., i][seg == i] = 1\n",
    "plt.imshow(b)\n",
    "plt.axis('off')\n",
    "plt.savefig('bv.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662600a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Red Traffic light birdview binary mask\n",
    "plt.imshow(frame_of_interest['birdview'][:,:,2])\n",
    "plt.axis('off')\n",
    "plt.savefig('bvtl.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d2ad0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_frame(frame, i):\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (int(0.1*frame.shape[0]), int(0.9*frame.shape[0]))\n",
    "    fontScale              = 1\n",
    "    fontColor              = [0,255,0]\n",
    "    fontColor2              = [255,0,0]\n",
    "    lineType               = 2\n",
    "    printed_frame = cv2.putText(frame.copy(),'Frame: '+str(i), \n",
    "            bottomLeftCornerOfText, font, fontScale, fontColor, lineType);\n",
    "    return printed_frame\n",
    "\n",
    "video = cv2.VideoWriter('videos/dataset_23_09_overview.avi', 0, 10, (384, 160))\n",
    "for i in range(int(out['len'].decode())):\n",
    "    drawn_frame = draw_frame(decode_frame(i)['rgb'], i)\n",
    "    video.write(drawn_frame)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb49370",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#from IPython.core.display import Video\n",
    "#Video(\"videos/dataset_23_09_overview.mp4\", embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e5c59",
   "metadata": {},
   "source": [
    "## 2. Waypoints computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a5d22",
   "metadata": {},
   "source": [
    "### 2.1 Tools for transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df729e8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Location():\n",
    "    def __init__(self, x, y, z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "    def __repr__(self,):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self,):\n",
    "        return \"Location(x={}, y={}, z={})\".format(self.x, self.y, self.z)\n",
    "\n",
    "class Rotation():\n",
    "    def __init__(self, p, y, r):\n",
    "        self.pitch = p\n",
    "        self.yaw = y\n",
    "        self.roll = r\n",
    "\n",
    "    def __repr__(self,):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Rotation(pitch={}, yaw={}, roll={})\".format(self.pitch, self.yaw, self.roll)\n",
    "\n",
    "class Transform():\n",
    "    def __init__(self, loc, rot):\n",
    "        self.location = loc\n",
    "        self.rotation = rot\n",
    "\n",
    "    def __repr__(self,):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self,):\n",
    "        return \"Transform({}, {})\".format(self.location, self.rotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7da42f",
   "metadata": {},
   "source": [
    "### 2.2 Compute waypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcdc16",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def project_vehicle(x, y, z, ori_x, ori_y, ori_z):\n",
    "    pos = np.array([x,y,z])\n",
    "    ori = np.array([ori_x, ori_y, ori_z])\n",
    "    ori /= np.linalg.norm(ori)  # Make unit vector\n",
    "\n",
    "    new_pos = pos + 4 * ori\n",
    "    return converter.convert(np.array([new_pos]))\n",
    "\n",
    "def interpolate_waypoints(points):\n",
    "    points = points[:, :2]\n",
    "\n",
    "    # Fit cubic function through points\n",
    "    z = np.polyfit(points[:, 0], points[:, 1], 2)\n",
    "    p = np.poly1d(z)\n",
    "\n",
    "    # Keep interpolating until we have 5 points\n",
    "    while points.shape[0] < 5:\n",
    "        points_2 = np.vstack([points[0], points[:-1]])\n",
    "        max_id = np.argmax(np.linalg.norm(points-points_2, axis=1))\n",
    "        _x = np.mean([points[max_id], points_2[max_id]], axis=0)[0]\n",
    "        points = np.insert(points, max_id, np.array([_x, p(_x)]), 0)\n",
    "\n",
    "    return points\n",
    "\n",
    "def get_waypoints(REF_FRAME, world_x, world_y, world_z, ori_x, ori_y, ori_z, GAP=5):\n",
    "    if decode_frame(REF_FRAME)['trafficlights']:\n",
    "        vehicle_proj = project_vehicle(world_x, world_y, world_z, ori_x, ori_y, ori_z)\n",
    "        output = np.array([vehicle_proj[0] for _ in range(5)])\n",
    "        return output\n",
    "\n",
    "    output = []\n",
    "    for i in range(REF_FRAME, (REF_FRAME + (N_STEP+1+BUFFER*GAP)), GAP):\n",
    "        if len(output) == N_STEP:\n",
    "            break\n",
    "\n",
    "        x, y, z = decode_frame(i)['measurements'][:3]\n",
    "        image_coords = converter.convert(np.array([[x, y, z]]))\n",
    "        if len(image_coords) > 0:\n",
    "            output.append(image_coords[0])\n",
    "\n",
    "    if len(output) < 2:\n",
    "        # First try with smaller GAP\n",
    "        if GAP == 5:\n",
    "            return get_waypoints(REF_FRAME, world_x, world_y, world_z, ori_x, ori_y, ori_z, GAP=1)\n",
    "\n",
    "        vehicle_proj = project_vehicle(world_x, world_y, world_z, ori_x, ori_y, ori_z)\n",
    "        output = np.array([vehicle_proj[0] for _ in range(5)])\n",
    "        return output\n",
    "\n",
    "    if len(output) >= 2 and len(output) < 5:\n",
    "        return interpolate_waypoints(np.array(output))\n",
    "\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a4dfd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# REF_FRAME = 800\n",
    "N_STEP = 5\n",
    "BUFFER = 40\n",
    "N_DATASET_CATEGORIES = 9 #(used to be 7)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "all_wp = []\n",
    "#N = int((len(out)-1)/7)\n",
    "N = int((len(out)-1)/N_DATASET_CATEGORIES) - 1\n",
    "for frame in tqdm(range(N - (N_STEP * BUFFER) - 1)):\n",
    "        # Extract world coordinates from dataset\n",
    "        world_coords = decode_frame(frame)['measurements']\n",
    "        world_x, world_y, world_z, ori_x, ori_y, ori_z, _, _, _, cam_x, cam_y, cam_z, cam_yaw, cam_roll, cam_pitch = world_coords[:15]\n",
    "\n",
    "        sensor_transform = Transform(Location(cam_x, cam_y, cam_z), Rotation(cam_yaw, cam_roll, cam_pitch))\n",
    "        converter = CoordinateConverter(sensor_transform, fov=120)\n",
    "\n",
    "        image_coord_wp = get_waypoints(frame, world_x, world_y, world_z, ori_x, ori_y, ori_z)\n",
    "\n",
    "        all_wp.append(image_coord_wp[:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9bfa35",
   "metadata": {},
   "source": [
    "## 3. Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d406cae",
   "metadata": {},
   "source": [
    "### 3.1 Segmentation from 2D to ND "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ece8d8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 13\n",
    "N_CLASSES_COMBINED = 6\n",
    "KEEP_CLASSES = {4,6,7,10,12}\n",
    "N_TRAFFIC_LIGHT_STATES = 1\n",
    "\n",
    "def seg2D_to_ND_combined(seg, tl_info):\n",
    "    seg = seg[:, :, 0]  # CARLA stores segmentation values in R channel\n",
    "    mask = np.zeros((*seg.shape, N_CLASSES_COMBINED + N_TRAFFIC_LIGHT_STATES))\n",
    "\n",
    "    for i, seg_class in enumerate(KEEP_CLASSES):\n",
    "        mask[..., i][seg == seg_class] = 1\n",
    "\n",
    "    TO_COMBINE = set(range(N_CLASSES))-KEEP_CLASSES\n",
    "    for i in TO_COMBINE:\n",
    "        mask[..., len(KEEP_CLASSES)] += seg==i\n",
    "\n",
    "    if tl_info == 0:\n",
    "        return mask\n",
    "\n",
    "    # Select channel and set binary mask, 12 is traffic sign class\n",
    "    mask[..., N_CLASSES_COMBINED][seg == 12] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "def seg2D_to_ND(seg, tl_info, combine=False):\n",
    "    \"\"\"Converts 2D segmentation image to ND array with N boolean masks.\n",
    "    Where N corresponds to number of segmentation classes.\"\"\"\n",
    "    if combine:\n",
    "        return seg2D_to_ND_combined(seg, tl_info)\n",
    "\n",
    "    seg = seg[:, :, 0]  # CARLA stores segmentation values in R channel\n",
    "    mask = np.zeros((*seg.shape, N_CLASSES + N_TRAFFIC_LIGHT_STATES))\n",
    "\n",
    "    for i in range(N_CLASSES):\n",
    "        mask[..., i][seg == i] = 1\n",
    "\n",
    "    if tl_info == 0:\n",
    "        return mask\n",
    "\n",
    "    # Select channel and set binary mask, 12 is traffic sign class\n",
    "    mask[..., N_CLASSES][seg == 12] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "#UNUSED\n",
    "def seg2D_to_ND_new(seg, tl_info, combine=False):\n",
    "    \"\"\"Converts 2D segmentation image to ND array with N boolean masks.\n",
    "    Where N corresponds to number of segmentation classes.\"\"\"\n",
    "    if combine:\n",
    "        return seg2D_to_ND_combined(seg, tl_info)\n",
    "\n",
    "    seg = seg[:, :, 0]  # CARLA stores segmentation values in R channel\n",
    "    mask = np.zeros((*seg.shape, N_CLASSES))\n",
    "\n",
    "    # Do not add traffic light state yet\n",
    "    for i in range(N_CLASSES-1):\n",
    "        mask[..., i][seg == i] = 1\n",
    "\n",
    "    # Add traffic light state, 12 is traffic sign class\n",
    "    mask[..., 12][seg == 12] = tl_info\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec70aa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_CLASSES=5\n",
    "a= np.random.randint(N_CLASSES, size=(10,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02095ff",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask = np.zeros((*a.shape, N_CLASSES))\n",
    "mask.shape\n",
    "\n",
    "# Do not add traffic light state yet\n",
    "for i in range(N_CLASSES):\n",
    "    mask[..., i][a == i] = 5\n",
    "    print(mask[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82767ca3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask[:,:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad62de",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tc = seg2D_to_ND_combined(decode_frame(N)['segmentation'], decode_frame(N)['trafficlights'])\n",
    "plt.imshow(tc[..., -2])\n",
    "plt.show()\n",
    "tc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52100ff1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = seg2D_to_ND(decode_frame(N)['segmentation'], decode_frame(N)['trafficlights'], combine=False)\n",
    "plt.imshow(t[..., -2])\n",
    "plt.show()\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb35427a",
   "metadata": {},
   "source": [
    "### 3.2 Down-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f056822",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def down_scale(img):\n",
    "    new_shape = (img.shape[0]//2, img.shape[1]//2)\n",
    "    img = np.moveaxis(img, 1, 0)\n",
    "    img = cv2.resize(img.astype(np.float32), new_shape)\n",
    "    img = np.moveaxis(img, 1, 0)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab0bb2",
   "metadata": {},
   "source": [
    "### 3.3 Augmentation sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274fd14",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "\n",
    "#def affine(image):\n",
    "#    aug = iaa.Affine(translate_px={\"x\": (-30, 30), \"y\": (0, -5)}, scale={\"x\": (1, 1.15), \"y\": (1, 1.15)}, mode='reflect')\n",
    "#    return aug(images=image)\n",
    "\n",
    "# def dropout(image):\n",
    "#     aug = iaa.Dropout(p=(0, 0.1), per_channel=0.5)\n",
    "#     return aug(images=image)\n",
    "\n",
    "# def blur(image):\n",
    "#     aug = iaa.MotionBlur(k=5, angle=[-90, 0, 90])\n",
    "#     return aug(images=image)\n",
    "\n",
    "sometimes = lambda aug: iaa.Sometimes(0.33, aug)\n",
    "# seq = iaa.Affine(translate_px={\"x\": (-15, 15), \"y\": (0, -5)}, scale={\"x\": (1, 1.15), \"y\": (1, 1.15)}, mode='reflect')\n",
    "seq = iaa.Sequential(\n",
    "        [\n",
    "            sometimes(\n",
    "                iaa.Affine(\n",
    "                    translate_px={\"x\": (-15, 15), \"y\": (0, -5)},\n",
    "                    scale={\"x\": (1, 1.15), \"y\": (1, 1.15)},\n",
    "                    mode='reflect')\n",
    "            ),\n",
    "            sometimes(\n",
    "                iaa.Dropout(\n",
    "                    p=(0, 0.1),\n",
    "                    per_channel=0.5)\n",
    "            ),\n",
    "            sometimes(\n",
    "                iaa.MotionBlur(\n",
    "                    k=(3,5),\n",
    "                    angle=[-90, 0, 90])\n",
    "            )\n",
    "        ],\n",
    "    random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3afe782",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Keypoint objects from waypoints so that we can apply to them the same augmentation sequence as the image\n",
    "def points_to_keypoints(points, shape):\n",
    "    kps = KeypointsOnImage([\n",
    "        Keypoint(x=points[0][0], y=points[0][1]),\n",
    "        Keypoint(x=points[1][0], y=points[1][1]),\n",
    "        Keypoint(x=points[2][0], y=points[2][1]),\n",
    "        Keypoint(x=points[3][0], y=points[3][1]),\n",
    "        Keypoint(x=points[4][0], y=points[4][1])\n",
    "        ], shape=shape)\n",
    "\n",
    "    return kps\n",
    "\n",
    "# Apply augmentation sequence to both image and waypoints\n",
    "def augment_image(image, points, redo=0):\n",
    "    if redo >= 5:\n",
    "        print(\"J\")\n",
    "        return image, points\n",
    "\n",
    "    image_aug, p_aug = seq(image=down_scale(image), keypoints=points_to_keypoints(points/2, (80, 192)))\n",
    "    temp = p_aug.to_xy_array()\n",
    "    if not np.all((temp[:, 0] <= 192) & (temp[:, 1] <= 80)):\n",
    "        return augment_image(image, points, redo=redo+1)\n",
    "\n",
    "    return image_aug, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445dfa3b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# view image (before/after) augmentation\n",
    "\n",
    "# def plot_augmentation(original, augmented):\n",
    "#     plt.figure(figsize=(12,6))\n",
    "#     plt.title(\"Original\")\n",
    "#     plt.imshow(original)\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure(figsize=(12,6))\n",
    "#     plt.title(\"Augmented\")\n",
    "#     plt.imshow(augmented)\n",
    "#     plt.show()\n",
    "    \n",
    "# # Intermediate overview\n",
    "# b = decode_frame(1)['segmentation']\n",
    "# b = seg2D_to_ND(b, 0)\n",
    "# b = down_scale(b)\n",
    "\n",
    "# plot_augmentation(b[:, :, 6:9], seq(image=b)[:, : ,6:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2878e300",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# view waypoints after augmentation\n",
    "\n",
    "# for i in range(0, 500, 100):\n",
    "#     temp_img = decode_frame(i)['segmentation']\n",
    "#     temp_img = seg2D_to_ND(temp_img, 0)\n",
    "#     img_aug, points_aug = augment_image(temp_img, all_wp[i])\n",
    "#     plt.scatter(points_aug[:, 0], points_aug[:, 1])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371211",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imgs, new_kps = seq(images=[down_scale(decode_frame(i)['segmentation'][:, :, 0]) for i in range(245, 255, 10)], keypoints=[points_to_keypoints(all_wp[i]/2, (80, 192)) for i in range(0, 100, 10)])\n",
    "for img, new_kp in zip(imgs, new_kps):\n",
    "    plt.imshow(img)\n",
    "    points_temp = new_kp.to_xy_array()\n",
    "    plt.scatter(points_temp[:, 0], points_temp[:, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee03e5",
   "metadata": {},
   "source": [
    "## 4. Final results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c1749",
   "metadata": {},
   "source": [
    "### 4.1 View final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190f9f1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_results(ref_frame_id, next_frame_id, locations):\n",
    "    plt.title(\"NEXT FRAME ({})\".format(next_frame_id))\n",
    "    plt.imshow(decode_frame(next_frame_id)['segmentation'][:, :, 0])\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.title(\"REF FRAME ({}) WITH PROJECTIONS\".format(ref_frame_id))\n",
    "    plt.imshow(decode_frame(ref_frame_id)['segmentation'][:, :, 0])\n",
    "    for i, location in enumerate(locations):\n",
    "        plt.scatter(location[:, 0], location[:, 1], label=\"projection {}\".format(i))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdac1b0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#plot_results(N, i, [all_wp[N]])\n",
    "plot_results(155, 160, [all_wp[155]])\n",
    "# plt.imshow(down_scale(decode_frame(N)['segmentation'][:, :, 0]))\n",
    "# temp_wp = all_wp[N].copy()\n",
    "\n",
    "# temp_wp /= 2\n",
    "# # temp_wp[:, 0] /= 2\n",
    "# # temp_wp[:, 1] /= 2\n",
    "\n",
    "# plt.scatter(temp_wp[:, 0], temp_wp[:, 1], s=1)\n",
    "# plt.scatter(temp_wp[:, 0], temp_wp[:, 1]-2, s=1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5fa8dd",
   "metadata": {},
   "source": [
    "### 4.2 Save final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489254fb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "R = 1\n",
    "\n",
    "#video = cv2.VideoWriter('imgs_noise_test/test_video_noise_2.avi', 0, 10, (192, 80))\n",
    "video = cv2.VideoWriter('noise/test_video_noise_2.avi', 0, 10, (192, 80))\n",
    "\n",
    "for i, wp in tqdm(enumerate(all_wp)):\n",
    "    # Down-scaling image (x0.5)\n",
    "    img = down_scale(decode_frame(i)['segmentation'][:, :, 0])\n",
    "    # Accordingly down-scaling waypoints (x0.5)\n",
    "    for x, y in wp:\n",
    "        x = int(x/2)\n",
    "        y = int(y/2)\n",
    "        img[y - R: y + R + 1, x - R: x + R + 1] = 12\n",
    "    \n",
    "    norm_image = cv2.normalize(img, None, alpha=0, beta=250, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "    imgC = cv2.applyColorMap(norm_image, cv2.COLORMAP_JET)\n",
    "    #plt.imshow(imgC)\n",
    "    #plt.show()\n",
    "    video.write(imgC)\n",
    "    #cv2.imwrite('imgs_noise_test/frame_{}.png'.format(i),  imgC)\n",
    "    cv2.imwrite('noise/frame_{}.png'.format(i),  imgC)\n",
    "    \n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a825e7",
   "metadata": {},
   "source": [
    "## 5. Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81319f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PIXEL_OFFSET = 10\n",
    "\n",
    "def draw_msra_gaussian(heatmap, center, sigma):\n",
    "    tmp_size = sigma * 3\n",
    "    mu_x = int(center[0] + 0.5)\n",
    "    mu_y = int(center[1] + 0.5)\n",
    "    w, h = heatmap.shape[0], heatmap.shape[1]\n",
    "    ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]\n",
    "    br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]\n",
    "    if ul[0] >= h or ul[1] >= w or br[0] < 0 or br[1] < 0:\n",
    "        return heatmap\n",
    "    size = 2 * tmp_size + 1\n",
    "    x = np.arange(0, size, 1, np.float32)\n",
    "    y = x[:, np.newaxis]\n",
    "    x0 = y0 = size // 2\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "    g_x = max(0, -ul[0]), min(br[0], h) - ul[0]\n",
    "    g_y = max(0, -ul[1]), min(br[1], w) - ul[1]\n",
    "    img_x = max(0, ul[0]), min(br[0], h)\n",
    "    img_y = max(0, ul[1]), min(br[1], w)\n",
    "    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(\n",
    "      heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]],\n",
    "      g[g_y[0]:g_y[1], g_x[0]:g_x[1]])\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def world_to_pixel(\n",
    "        x,y,ox,oy,ori_ox, ori_oy,\n",
    "        pixels_per_meter=5, offset=(-80,160), size=320, angle_jitter=15):\n",
    "    pixel_dx, pixel_dy = (x-ox)*pixels_per_meter, (y-oy)*pixels_per_meter\n",
    "\n",
    "    pixel_x = pixel_dx*ori_ox+pixel_dy*ori_oy\n",
    "    pixel_y = -pixel_dx*ori_oy+pixel_dy*ori_ox\n",
    "\n",
    "    pixel_x = size-pixel_x\n",
    "\n",
    "    return np.array([pixel_x, pixel_y]) + offset\n",
    "\n",
    "def test_get_item(bird_view, segmentation, tl_info, measurement, segs=False):\n",
    "    crop_x_jitter = 5\n",
    "    crop_y_jitter = 0\n",
    "    angle_jitter =  5\n",
    "    img_size = 320\n",
    "    crop_size = 192\n",
    "    crop_size_y = 80\n",
    "    down_ratio = 4\n",
    "    gap = 5\n",
    "    gaussian_radius = 1.0\n",
    "    n_step = 5\n",
    "    segmentation = seg2D_to_ND(segmentation, tl_info, combine=False)\n",
    "    rgb_image = None\n",
    "\n",
    "    ox, oy, oz, ori_ox, ori_oy, vx, vy, vz, _, _, _, _, _, _, ax, ay, az, cmd, steer, throttle, brake, manual, gear  = measurement\n",
    "    speed = np.linalg.norm([vx,vy,vz])\n",
    "\n",
    "    oangle = np.arctan2(ori_oy, ori_ox)\n",
    "    delta_angle = np.random.randint(-angle_jitter,angle_jitter+1)\n",
    "    dx = np.random.randint(-crop_x_jitter,crop_x_jitter+1)\n",
    "    dy = np.random.randint(0,crop_y_jitter+1) - PIXEL_OFFSET\n",
    "\n",
    "    o_camx = ox + ori_ox*2\n",
    "    o_camy = oy + ori_oy*2\n",
    "\n",
    "#     if segs:\n",
    "    pixel_ox = 192\n",
    "    pixel_oy = 130\n",
    "\n",
    "    # RANDOM WARPING\n",
    "    segmentation = cv2.warpAffine(\n",
    "            segmentation,\n",
    "            cv2.getRotationMatrix2D((pixel_ox,pixel_oy), delta_angle, 1.0),\n",
    "            segmentation.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    center_x, center_y = pixel_ox, pixel_oy-crop_size_y//2\n",
    "    segmentation = segmentation[\n",
    "            dy+center_y-crop_size_y//2:dy+center_y+crop_size_y//2,\n",
    "            dx+center_x-crop_size//2:dx+center_x+crop_size//2]\n",
    "\n",
    "    angle = np.arctan2(ori_oy, ori_ox) + np.deg2rad(delta_angle)\n",
    "    ori_ox, ori_oy = np.cos(angle), np.sin(angle)\n",
    "\n",
    "    locations = []\n",
    "    orientations = []\n",
    "\n",
    "    # LOCATION MODIFICATION\n",
    "    for dt in range(gap, gap*(n_step+1), gap):\n",
    "        f_measurement = decode_frame(N+dt)['measurements']\n",
    "        x, y, z, ori_x, ori_y = f_measurement[:5]\n",
    "#         x, y, z, ori_x, ori_y, ori_z = f_measurement[:6]\n",
    "#         rot, loc = rotation(ori_x, ori_y, ori_z), np.array([x, y, z])\n",
    "#         inv_m = get_inv_matrix(rot, loc)\n",
    "\n",
    "        pixel_y, pixel_x = world_to_pixel(x,y,ox,oy,ori_ox,ori_oy,size=160, offset=(-80,192))\n",
    "        pixel_x = pixel_x - (384-crop_size)//2\n",
    "        pixel_y = crop_size_y - (160-pixel_y)+70\n",
    "\n",
    "        pixel_x -= dx\n",
    "        pixel_y -= dy\n",
    "\n",
    "        angle = np.arctan2(ori_y, ori_x) - np.arctan2(ori_oy, ori_ox)\n",
    "        ori_dx, ori_dy = np.cos(angle), np.sin(angle)\n",
    "\n",
    "        locations.append([x, y, z])\n",
    "        orientations.append([ori_dx, ori_dy])\n",
    "\n",
    "\n",
    "    # Create mask\n",
    "    output_size = crop_size // down_ratio\n",
    "    heatmap_mask = np.zeros((n_step, output_size, output_size), dtype=np.float32)\n",
    "    regression_offset = np.zeros((n_step,2), np.float32)\n",
    "    indices = np.zeros((n_step), dtype=np.int64)\n",
    "\n",
    "    for i, (pixel_x, pixel_y, _) in enumerate(locations):\n",
    "        center = np.array(\n",
    "                [pixel_x / down_ratio, pixel_y / down_ratio],\n",
    "                dtype=np.float32)\n",
    "        center = np.clip(center, 0, output_size-1)\n",
    "        center_int = np.rint(center)\n",
    "\n",
    "        draw_msra_gaussian(heatmap_mask[i], center_int, gaussian_radius)\n",
    "        regression_offset[i] = center - center_int\n",
    "        indices[i] = center_int[1] * output_size + center_int[0]\n",
    "    out = []\n",
    "    out.append([segmentation, bird_view, np.array(locations), cmd, speed])\n",
    "#     else:\n",
    "    pixel_ox = 160\n",
    "    pixel_oy = 260\n",
    "\n",
    "\n",
    "    # RANDOM WARPING\n",
    "    bird_view = cv2.warpAffine(\n",
    "            bird_view,\n",
    "            cv2.getRotationMatrix2D((pixel_ox,pixel_oy), delta_angle, 1.0),\n",
    "            bird_view.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "    # RANDOM CROPPING\n",
    "    center_x, center_y = 160, 260-crop_size//2\n",
    "    bird_view = bird_view[\n",
    "            dy+center_y-crop_size//2:dy+center_y+crop_size//2,\n",
    "            dx+center_x-crop_size//2:dx+center_x+crop_size//2]\n",
    "\n",
    "    angle = np.arctan2(ori_oy, ori_ox) + np.deg2rad(delta_angle)\n",
    "    ori_ox, ori_oy = np.cos(angle), np.sin(angle)\n",
    "\n",
    "    locations = []\n",
    "    orientations = []\n",
    "\n",
    "    # LOCATION MODIFICATION\n",
    "    for dt in range(gap, gap*(n_step+1), gap):\n",
    "        f_measurement = decode_frame(N+dt)['measurements']\n",
    "        x, y, z, ori_x, ori_y = f_measurement[:5]\n",
    "\n",
    "#         x, y, z, ori_x, ori_y, ori_z = f_measurement[:6]\n",
    "#         rot, loc = rotation(ori_x, ori_y, ori_z), np.array([x, y, z])\n",
    "#         inv_m = get_inv_matrix(rot, loc)\n",
    "\n",
    "        pixel_y, pixel_x = world_to_pixel(x,y,ox,oy,ori_ox,ori_oy,size=img_size)\n",
    "        pixel_x = pixel_x - (img_size-crop_size)//2\n",
    "        pixel_y = crop_size - (img_size-pixel_y)+70\n",
    "\n",
    "        pixel_x -= dx\n",
    "        pixel_y -= dy\n",
    "\n",
    "        angle = np.arctan2(ori_y, ori_x) - np.arctan2(ori_oy, ori_ox)\n",
    "        ori_dx, ori_dy = np.cos(angle), np.sin(angle)\n",
    "\n",
    "        locations.append([x, y, z])\n",
    "        orientations.append([ori_dx, ori_dy])\n",
    "\n",
    "\n",
    "    # Create mask\n",
    "    output_size = crop_size // down_ratio\n",
    "    heatmap_mask = np.zeros((n_step, output_size, output_size), dtype=np.float32)\n",
    "    regression_offset = np.zeros((n_step,2), np.float32)\n",
    "    indices = np.zeros((n_step), dtype=np.int64)\n",
    "\n",
    "    for i, (pixel_x, pixel_y, _) in enumerate(locations):\n",
    "        center = np.array(\n",
    "                [pixel_x / down_ratio, pixel_y / down_ratio],\n",
    "                dtype=np.float32)\n",
    "        center = np.clip(center, 0, output_size-1)\n",
    "        center_int = np.rint(center)\n",
    "\n",
    "        draw_msra_gaussian(heatmap_mask[i], center_int, gaussian_radius)\n",
    "        regression_offset[i] = center - center_int\n",
    "        indices[i] = center_int[1] * output_size + center_int[0]\n",
    "\n",
    "    out.append([segmentation, bird_view, np.array(locations), cmd, speed])\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c23cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_FIG = 6\n",
    "out_temp = []\n",
    "for i in range(N_FIG):\n",
    "    N = i + 10\n",
    "    temp = test_get_item(decode_frame(N)['birdview'], decode_frame(N)['segmentation'], decode_frame(N)['trafficlights'], decode_frame(N)['measurements'])\n",
    "    out_temp.append(temp)\n",
    "\n",
    "out_temp = np.array(out_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bf0be",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "REF_FRAME = 0\n",
    "NEXT_FRAME = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579d89a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extract world coordinates from dataset\n",
    "world_coords = decode_frame(REF_FRAME)['measurements']\n",
    "world_x, world_y, world_z, _, _, _, _, _, cam_x, cam_y, cam_z, cam_yaw, cam_roll, cam_pitch = world_coords[:14]\n",
    "\n",
    "print(\"CURRENT LOCATION:\", world_x, world_y, world_z)\n",
    "# Get sensor transform\n",
    "sensor_transform = Transform(Location(cam_x, cam_y, cam_z), Rotation(cam_yaw, cam_roll, cam_pitch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2c7c1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,60))\n",
    "\n",
    "for i in range(N_FIG):\n",
    "    # NEW SEG\n",
    "    plt.subplot(N_FIG, 2, (i*2)+1)\n",
    "    plt.imshow(out_temp[i][0][0][..., 6:9])\n",
    "    plt.scatter(out_temp[i][0][2][:,0], out_temp[i][0][2][:,1])\n",
    "\n",
    "    # OLD BIRDVIEW\n",
    "    plt.subplot(N_FIG, 2, (i*2)+2)\n",
    "    plt.imshow(out_temp[i][1][1][:, :, :3])\n",
    "    plt.scatter(out_temp[i][1][2][:,0], out_temp[i][1][2][:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef408e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,20))\n",
    "\n",
    "for i in range(N_FIG):\n",
    "    # NEW SEG\n",
    "    plt.subplot(N_FIG, 2, (i*2)+1)\n",
    "    plt.imshow(out_temp[i][0][0][..., 6:9])\n",
    "    plt.scatter(out_temp[i][0][2][:,0], out_temp[i][0][2][:,1])\n",
    "\n",
    "    # OLD BIRDVIEW\n",
    "    plt.subplot(N_FIG, 2, (i*2)+2)\n",
    "    plt.imshow(out_temp[i][1][1][:, :, :3])\n",
    "    plt.scatter(out_temp[i][1][2][:,0], out_temp[i][1][2][:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86a0868",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Segemetnation tests\n",
    "\n",
    "for i in range(1000):\n",
    "    temp_img = decode_frame(i)['segmentation']\n",
    "    temp_tl = decode_frame(i)['trafficlights']\n",
    "    \n",
    "    if temp_tl:\n",
    "        print(i)\n",
    "        break\n",
    "    \n",
    "\n",
    "temp_img = decode_frame(759)['segmentation']\n",
    "temp_tl = decode_frame(759)['trafficlights']\n",
    "\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(temp_img[:, :, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"OLD TL state channel\")\n",
    "plt.imshow(seg2D_to_ND(temp_img, 1)[:, :, 13:14])\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"OLD TL channel\")\n",
    "plt.imshow(seg2D_to_ND(temp_img, 1)[:, :, 12:13])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"NEW TL (state) channel\")\n",
    "plt.imshow(seg2D_to_ND_new(temp_img, 0)[:, :, 12:13])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(seg2D_to_ND_new(temp_img, 0)[:, :, 10:13])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
